{
  "overall": {
    "accuracy": 0.845,
    "f1": 0.8577256501784803,
    "tpr": 0.9344444444444444,
    "fpr": 0.24444444444444444,
    "auroc": 0.9451271604938272,
    "auprc": 0.950357377992491,
    "threshold": -5.071885583068555e-05
  },
  "per_dataset": {
    "XSTest_safe": {
      "accuracy": 0.7,
      "f1": 0.0,
      "tpr": 0.0,
      "fpr": 1.0,
      "auroc": 0.0,
      "auprc": 0.0,
      "size": 250,
      "safe_samples": 250,
      "unsafe_samples": 0,
      "mean_detection_score": -5.7197972637368366e-05
    },
    "FigTxt_safe": {
      "accuracy": 0.5166666666666667,
      "f1": 0.0,
      "tpr": 0.0,
      "fpr": 0.0,
      "auroc": 0.0,
      "auprc": 0.0,
      "size": 300,
      "safe_samples": 300,
      "unsafe_samples": 0,
      "mean_detection_score": -5.4668864322593436e-05
    },
    "VQAv2": {
      "accuracy": 1.0,
      "f1": 0.0,
      "tpr": 0.0,
      "fpr": 0.0,
      "auroc": 0.0,
      "auprc": 0.0,
      "size": 350,
      "safe_samples": 350,
      "unsafe_samples": 0,
      "mean_detection_score": -6.751990440534428e-05
    },
    "XSTest_unsafe": {
      "accuracy": 0.72,
      "f1": 0.8372093023255814,
      "tpr": 1.0,
      "fpr": 0.0,
      "auroc": 0.0,
      "auprc": 0.0,
      "size": 200,
      "safe_samples": 0,
      "unsafe_samples": 200,
      "mean_detection_score": -4.5474080252461135e-05
    },
    "FigTxt_unsafe": {
      "accuracy": 0.9914285714285714,
      "f1": 0.9956958393113343,
      "tpr": 1.0,
      "fpr": 0.0,
      "auroc": 0.0,
      "auprc": 0.0,
      "size": 350,
      "safe_samples": 0,
      "unsafe_samples": 350,
      "mean_detection_score": -1.9281040295027196e-05
    },
    "VAE": {
      "accuracy": 1.0,
      "f1": 1.0,
      "tpr": 1.0,
      "fpr": 0.0,
      "auroc": 0.0,
      "auprc": 0.0,
      "size": 200,
      "safe_samples": 0,
      "unsafe_samples": 200,
      "mean_detection_score": 0.0001086307893274352
    },
    "JailbreakV-28K": {
      "accuracy": 1.0,
      "f1": 1.0,
      "tpr": 1.0,
      "fpr": 0.0,
      "auroc": 0.0,
      "auprc": 0.0,
      "size": 150,
      "safe_samples": 0,
      "unsafe_samples": 150,
      "mean_detection_score": 0.00012841699935961515
    }
  },
  "config": {
    "latent_dim": 128,
    "batch_size": 16,
    "learning_rate": 0.0001,
    "num_epochs": 100,
    "seed": 42,
    "vlm_model": "openai/clip-vit-large-patch14"
  }
}